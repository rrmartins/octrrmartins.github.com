<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ruby 1.9 | Rodrigo Martins]]></title>
  <link href="http://rrmartins.com/blog/categories/ruby-1-dot-9/atom.xml" rel="self"/>
  <link href="http://rrmartins.com/"/>
  <updated>2015-09-21T10:39:30-03:00</updated>
  <id>http://rrmartins.com/</id>
  <author>
    <name><![CDATA[Rodrigo Martins]]></name>
    <email><![CDATA[rodrigo@rrmartins.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Threads e Concorrência - Exemplos de Threads - Part IV - #Ruby 1.9]]></title>
    <link href="http://rrmartins.com/blog/2012/11/04/threads-e-concorrencia-exemplos-de-threads-part-iv-number-ruby-1-dot-9/"/>
    <updated>2012-11-04T09:20:00-02:00</updated>
    <id>http://rrmartins.com/blog/2012/11/04/threads-e-concorrencia-exemplos-de-threads-part-iv-number-ruby-1-dot-9</id>
    <content type="html"><![CDATA[<!--more-->


<p>Hoje vamos continuar falando de <a href="http://www.ruby-doc.org/core-1.9.3/">Ruby</a>, é hora de nos aprofundar em um pouco de <strong>Threads e Concorrência</strong> agora <strong>Exemplos de Threads</strong>&hellip;</p>

<h4>Exemplos de Threads</h4>

<p>Agora que já passamos alguns post falando do modelo <code>Thread</code> e da API de <code>Thread</code> em Ruby, vamos dar uma olhada em alguns
exemplos reais de vários códigos de <code>threads</code>.</p>

<h3>Leitura de arquivos simultaneamente</h3>

<p>O uso mais comum de <code>threads</code> de Ruby é em programas que são IO. Eles permitem que os programas mantenham ocupado até
mesmo enquanto espera por alguma entrada do usuário, o sistema de arquivos, ou da rede. A seguir de código, por exemplo,
define um método <code>conread</code> (para leitura simultânea) que leva uma série de nomes de arquivos e retorna um mapa de <code>hash</code>
com esses nomes para o conteúdo desses arquivos. Ele usa <code>thread</code> para ler esses arquivos ao mesmo tempo, e é realmente
destinado a ser utilizado com o módulo <code>open-uri</code>, que permite que as URL&rsquo;s <code>HTTP</code> e <code>FTP</code> possam ser abertas com
<code>Kernel.open</code> e ler como se fossem arquivos:</p>

<pre><code class="ruby Lendo arquivos">
# Ler arquivos simultaneamente. Use com o módulo "open-uri" para buscar URLs.
# Passe uma matriz de nomes de arquivos. Retorna um mapa de nomes de arquivos de hash para o conteúdo.
def conread(filenames)
  h = {}            # hash vazio de resultados

  # Crie uma linha para cada arquivo
  filenames.each do |filename|      # Para cada arquivo chamado
    h[filename] = Thread.new do     # Criar um fio, mapa para filename
      open(filename) {|f| f.read }  # Abra e leia o arquivo
    end                             # valor da linha é o conteúdo do arquivo
  end

  # Percorre o hash, à espera de cada thread para completar.
  # Substitua a thread no hash com o seu valor (o conteúdo de arquivo)
  h.each_pair do |filename, thread|
    begin
      h[filename] = thread.value    # Mapa de nomes ao conteúdo do arquivo
    rescue
      h[filename] = $!              # Ou a exceção levantada
    end
  end
end
</code></pre>

<h3>Servidor A Multithreads</h3>

<p>Outra, quase canônico caso, o uso de <code>threads</code> é para escrever servidores que podem comunicar com mais do que um cliente
de cada vez. Vimos como fazer isto utilizando multiplexagem com Kernel.select, mas um pouco mais simples (Embora
possivelmente menos escalável) solução usa <code>threads</code>:</p>

<pre><code class="ruby Servidor a Multithreads">require 'socket'

# Este método espera um socket ligado a um cliente.
# Ele lê as linhas do cliente, inverte-los e envia-los de volta.
# Múltiplas Threads podem executar este método, ao mesmo tempo.
def handle_client(c)
  while true
    input = c.gets.chop     # Ler uma linha de entrada do cliente
    break if !input         # sai se tem muitas entradas
    break if input=="quit"  # ou se o cliente pede
    c.puts(input.reverse)   # Caso contrário, responde ao cliente.
    c.flush                 # Força a saída para fora
  end
  c.close                   # Fecha o socket cliente
end

server = TCPServer.open(2000) # Ouve na porta 2000

while true                    # Laço de servidores para sempre
  client = server.accept      # Espere um cliente para conectar
  Thread.start(client) do |c| # Inicia uma nova thread
    handle_client(c)          # E Lida com o clinete nessa Thread
  end
end
</code></pre>

<h3>Iteradores simultâneas</h3>

<p>Embora tarefas IO são o caso de uso típico para <code>threads</code> de Ruby, eles não se restringem aos que usam. O código a seguir
adiciona um método <code>conmap</code> (por mapa concorrente) para o modulo <code>Enumerável</code>. Ele funciona como mapa, mas processa cada
elemento da matriz de entrada com uma distinta <code>Thread</code>:</p>

<pre><code class="ruby Iterador Simultâneo">module Enumerable           # Abre o módulo Enumerable
  def conmap(&amp;block)        # Define um novo método que espera um block
    threads = []            # Começa com uma matriz vazia de threads
    self.each do |item|     # Para cada item enumerable
      # Chama o bloco em uma nova Thread, e lembra da Thread
      threads &lt;&lt; Thread.new { block.call(item) }
    end
    # Agora mapea o conjunto de Threads para os seus valores
    threads.map {|t| t.value } # E retorna a matriz de valores
  end
end
</code></pre>

<p>E aqui está uma versão concorrente similar do iterador de cada um:</p>

<pre><code class="ruby Módulo Enumerable">module Enumerable
  def concurrently
    map {|item| Thread.new { yield item }}.each {|t| t.join }
  end
end
</code></pre>

<p>O código é sucinto e desafiador: se você pode fazer sentido, você está bem em seu caminho para o domínio da sintaxe de
Ruby e iteradores Ruby.</p>

<p>Lembre-se que no Ruby 1.9, iteradores padrões que não são passado um bloco retorna um objeto enumerador. Isto significa
que, dado o método <code>concurrently</code> definido mais cedo e um objeto <code>Hash h</code>, podemos escrever:</p>

<pre><code class="ruby Método Concurrently">h.each_pair.concurrently {|*pair| process(pair)}
</code></pre>

<p>Até o proximo amigos!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Threads e Concorrência - Escalando Threads - Part III - #Ruby 1.9]]></title>
    <link href="http://rrmartins.com/blog/2012/10/28/threads-e-concorrencia-escalando-threads-part-iii-number-ruby-1-dot-9/"/>
    <updated>2012-10-28T15:04:00-02:00</updated>
    <id>http://rrmartins.com/blog/2012/10/28/threads-e-concorrencia-escalando-threads-part-iii-number-ruby-1-dot-9</id>
    <content type="html"><![CDATA[<!--more-->


<p>Hoje vamos continuar falando de <a href="http://www.ruby-doc.org/core-1.9.3/">Ruby</a>, é hora de nos aprofundar em um pouco de <strong>Threads e Concorrência</strong> agora <strong>Escalando Threads</strong>&hellip;</p>

<h2>Threads e Concorrência</h2>

<h3>Escalando Threads</h3>

<p>Intérpretes do Ruby(irb), muitas vezes têm mais <code>threads</code> para executar do que há CPU tem disponível para executá-los. Quando
o processamento paralelo verdadeiro não é possível, é simulado através da partilha de uma CPU entre <code>threads</code>. O processo para
a partilha de uma CPU entre as <code>threads</code> é chamado de escalonamento de <code>threads</code>. Dependendo da implementação e plataforma,
agendamento de <code>threads</code> pode ser feito pelo Intérprete do Ruby(irb), ou pode ser tratado pelo sistema operacional.</p>

<h4>Prioridades da Thread</h4>

<p>O primeiro fator que afeta o agendamento de <code>threads</code> é prioridades de <code>thread</code>: com a alta prioridade da <code>thread</code> são
agendadas antes de baixa prioridade de <code>thread</code>. Mais precisamente, uma <code>thread</code> só vai ficar o tempo de CPU, se não houver
maior prioridade de <code>thread</code> aguardando para ser executada.</p>

<p>Definir e consultar a prioridade de um objeto Ruby <code>Thread</code> com <code>priority=</code> e <code>priority</code>. Note-se que não há nenhuma maneira
de definir a prioridade de uma <code>thread</code> antes que ela comece a funcionar. Uma <code>thread</code> pode, no entanto, aumentar ou diminuir
sua própria prioridade como a primeira ação que toma.</p>

<p>Uma <code>thread</code> recém-criada começa com a mesma prioridade que a <code>thread</code> que a criou. A <code>thread</code> principal começa na prioridade
 0.</p>

<p>Como muitos aspectos de <code>threading</code>, prioridades de <code>threads</code> são depende da implementação do <code>Ruby</code> e do subjacente sistema
operacional. No Linux, por exemplo, <code>threads</code> não privilegiadas não pode ter as suas prioridades levantada ou abaixada. Assim,
no Ruby 1.9 (que usa <code>threads</code> nativas) no <code>Linux</code>, a definição de prioridades de <code>Thread</code> é ignorada.</p>

<h4>Aquisição de Thread e Thread.pass</h4>

<p>Quando várias <code>Threads</code> com a mesma prioridade precisam compartilhar a CPU, cabe a <code>thread</code> programada para decidir quando e
por quanto tempo, cada <code>thread</code> é executada. Alguns escalonadores são antecipadas, o que significa que elas permitem a <code>thread</code>
a ser executada apenas por um determinado período de tempo antes de permitir outra <code>thread</code> da mesma prioridade para ser
executada. Outros programadores não são preempção: uma vez que uma <code>thread</code> começa a correr, ela continua funcionando a menos
que durma, blocos para I/O, ou uma <code>thread</code> de maior prioridade acorda.</p>

<p>Se uma longa linha de computação liga (ou seja, aquela que nunca faz bloqueio para I/O) está em execução em um agendador
não preemptivo, ela vai &ldquo;morrer de fome&rdquo; as outras <code>threads</code> com a mesma prioridade, e elas nunca tem a chance de correr.
Para evitar esse problema, de longa duração <code>compute-bound</code> <code>threads</code> devem chamar periodicamente <code>Thread.pass</code> para pedir o
programador para produzir a CPU para outra <code>thread</code>.</p>

<p>Até a proxima amigos! :D</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Threads e Concorrência - Threads e Variáveis - Part II - #Ruby 1.9]]></title>
    <link href="http://rrmartins.com/blog/2012/10/28/threads-e-concorrencia-threads-e-variaveis-part-ii-number-ruby-1-dot-9/"/>
    <updated>2012-10-28T14:53:00-02:00</updated>
    <id>http://rrmartins.com/blog/2012/10/28/threads-e-concorrencia-threads-e-variaveis-part-ii-number-ruby-1-dot-9</id>
    <content type="html"><![CDATA[<!--more-->


<p>Hoje vamos continuar falando de <a href="http://www.ruby-doc.org/core-1.9.3/">Ruby</a>, é hora de nos aprofundar em um pouco de <strong>Threads e Concorrência</strong> agora <strong>Threads e Variáveis</strong>&hellip;</p>

<h2>Threads e Concorrência</h2>

<h3>Threads e Variáveis</h3>

<p>Uma das características-chave de <code>Thread</code> é que elas podem compartilhar o acesso a variáveis. Como <code>Threads</code> são definidas
por blocos, eles têm acesso a qualquer que seja variáveis ​​(variáveis ​​locais, variáveis ​​de instância, variáveis ​​globais e
 assim por diante) estão no escopo do bloco:</p>

<pre><code class="ruby Thread e Variavel">x = 0

t1 = Thread.new do
  # Esta Thread pode consultar e definir a variável x
end

t2 = Thread.new do
  # Esta Thread e também consulta e seta x
  # E pode consultar e definir T1 e T2 também.
end
</code></pre>

<p>Quando dois ou mais <code>Thread</code> de ler e escrever as mesmas variáveis ao mesmo tempo, elas devem tomar cuidado para que elas o
fazem corretamente. Nós vamos ter mais a dizer sobre isso quando consideramos a sincronização de <code>threads</code> abaixo.</p>

<h4>Thread-privadas variáveis</h4>

<p>Variáveis ​​definidas dentro do bloco de uma <code>thread</code> são particulares para essa <code>thread</code> e não são visíveis para qualquer
outra <code>thread</code>. Isto é simplesmente consequência de regras de variáveis de escopo ​​Ruby.</p>

<p>Muitas vezes queremos uma <code>Thread</code> tenha sua própria cópia privada de uma variável de modo a que o seu comportamento não se
altere se o valor do referido mude de variáveis. Considere o seguinte código, que tenta criar três tópicos que impressão (
respectivamente) os números 1, 2 e 3:</p>

<pre><code class="ruby Threads Privadas">n = 1
while n &lt;= 3
  Thread.new { puts n }
  n += 1
end
</code></pre>

<p>Em algumas circunstâncias, em algumas implementações, este código pode funcionar como o esperado e imprimir os números 1, 2 e
3. Em outras circunstâncias, ou em outras implementações, talvez não. É perfeitamente possível (se tópicos recentemente
criados não executa de imediato) para o código imprimir 4, 4, e 4, por exemplo. Cada thread lê uma cópia compartilhada da
variável n, e o valor ds mudanças de variáveis ​​como o loop é executado. O valor impresso pela <code>thread</code> depende de quando esse
segmento é executado em relação para a thread pai.</p>

<p>Para resolver este problema, passamos o valor atual de n para o método <code>Thread.new</code>, e atribuimos o atual valor da variável a
um parâmetro de bloco. Parâmetros de bloco são privados para o bloco, e este valor particular não é partilhado entre tópicos:</p>

<pre><code class="ruby Threads Privadas">n = 1
while n &lt;= 3
  # Obtem uma cópia privada do valor atual de n em x
  Thread.new(n) {|x| puts x }
  n += 1
end
</code></pre>

<p>Note-se que temos uma outra forma de resolver este problema é a utilização de um iterador em vez de um loop <code>while</code>. Neste
caso, o valor de <code>n</code> é modificado para particular para o bloco externo e nunca durante a execução desse bloco:</p>

<pre><code class="ruby Thread Privada com Interator">1.upto (3) {| n | Thread.new {puts n}}
</code></pre>

<h4>Variáveis ​​de Threads locais</h4>

<p>Algumas das variáveis especiais globais de Ruby são <code>thread</code> local: elas podem ter valores diferentes em <code>threads</code> diferentes.
<code>$SAFE</code> e <code>$~</code> são exemplos. Isto significa que, se dois <code>thread</code> estão realizando conconrrencia de expressão regular ao mesmo
tempo, eles vão ver diferentes valores de <code>$~</code>, e a realização de um jogo em um fio não irá interferir com os resultados de
um jogo executado na outra discussão.</p>

<p>A classe <code>Thread</code> provê <code>hash-like</code> como o comportamento. Ele define métodos de instância <code>[]</code> e <code>[]=</code> que permitem associar
valores arbitrários com qualquer símbolo. (Se você usar uma cadeia de caracteres em vez disso, ele será convertido em um
símbolo. Ao contrário <code>hashs</code> de verdade, a classe <code>Thread</code> só permite símbolos como chaves.) Os valores associados a estes
símbolos comportam-se como variáveis ​​de <code>Thread</code> locais. Eles não são privados como variáveis de block ​​locais porque qualquer
<code>Thread</code> pode pesquisar um valor em qualquer outra <code>Thread</code>. Mas eles não são variáveis partilhadas, uma vez que cada Thread
pode ter a sua própria cópia.</p>

<p>Como exemplo, suponha que nós criamos <code>thread</code> para download de arquivos de um servidor web. A <code>Thread</code> principal pode querer
monitorar o progresso do download. Para permitir isso, cada <code>Thread</code> pode fazer o seguinte:</p>

<pre><code class="ruby Thread de progresso">Thread.current[:progress] = bytes_received
</code></pre>

<p>A <code>Thread</code> principal poderia, então, determinar o total de bytes baixado com um código como este:</p>

<pre><code class="ruby Thread de progresso">total = 0
download_threads.each {|t| total += t[:progress] }
</code></pre>

<p>Junto com <code>[]</code> e <code>[]=</code>, <code>Thread</code> também define um método <code>key?</code> para testar se uma determinada chave existe para uma discussão
. Os métodos <code>keys</code> retorna uma matriz de símbolos que representam as chaves definidas para a <code>Thread</code>. Este código pode ser
melhor escrito como se segue, de modo que ela trabalhe de tópicos que ainda não começou a correr e não tenha definido a chave
:progress ainda:</p>

<pre><code class="ruby Thread de progresso">total = 0
download_threads.each {|t| total += t[:progress] if t.key?(:progress)}
</code></pre>

<p>Até a proxima galera! :D</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Threads e Concorrência - Part I - #Ruby 1.9]]></title>
    <link href="http://rrmartins.com/blog/2012/10/28/threads-e-concorrencia-part-i-number-ruby-1-dot-9/"/>
    <updated>2012-10-28T14:26:00-02:00</updated>
    <id>http://rrmartins.com/blog/2012/10/28/threads-e-concorrencia-part-i-number-ruby-1-dot-9</id>
    <content type="html"><![CDATA[<!--more-->


<p>Hoje vamos continuar falando de <a href="http://www.ruby-doc.org/core-1.9.3/">Ruby</a>, é hora de nos aprofundar em um pouco de <strong>Threads e Concorrência</strong> agora <strong>Thread Lifecycle</strong>&hellip;</p>

<h2>Threads e Concorrência</h2>

<p>Programas tradicionais têm uma única &ldquo;thread de execução&rdquo;: as declarações ou instruções que compõem o programa são executadas
sequencialmente até que o programa termina. Um programa multithread tem mais de uma <code>thread</code> de execução. Dentro de cada <code>
thread</code>, os comandos são executados sequencialmente, mas as próprias <code>threads</code> podem ser executadas em paralelo em uma
CPU multicore, por exemplo. Frequentemente (em um núcleo único, uma única CPU, por exemplo), várias <code>Threads</code> não são na
realidade executadas em paralelo, mas o paralelismo é simulada intercalando a execução das <code>threads</code>.</p>

<p>Programas como o software de processamento de imagem que fazem um monte de cálculos estão a ser dito <code>compute-bound</code>. Eles só
podem beneficiar de multithreading, se há realmente múltiplas CPUs para executar os cálculos em paralelo. A maioria dos
programas não são totalmente vinculados a computação, no entanto. Muitos, como navegadores web, passam a maior parte de seu
tempo de espera para a rede ou arquivo <code>I/O</code>. Programas como estes estão a ser dito <code>IO-bound</code>. Programas <code>IO-bound</code> pode ser
útil mesmo quando várias <code>threads</code> há apenas uma única CPU disponível. Um navegador pode tornar uma imagem em uma <code>thread</code>
enquanto outra <code>thread</code> está à espera para a próxima imagem para ser baixada da rede.</p>

<p>Ruby faz com que seja fácil de escrever programas <code>multi-threaded</code> com a <code>Class Thread</code>. Para iniciar uma nova <code>thread</code>,
apenas associa um bloco com uma chamada para <code>Thread.new</code>. Uma nova <code>thread</code> será criada para executar o código no bloco, e a
<code>thread</code> original retornará do <code>Thread.new</code> imediatamente e continuar a execução com a afirmação seguinte:</p>

<pre><code class="ruby Iniciando um thread"># Thread #1 está sendo executado aqui
Thread.new {
  # Thread #2 executa esse código
}
# Thread #1 executa esse código
</code></pre>

<p>Vamos começar nossa cobertura de <code>threads</code> explicando o modelo <code>Thread</code> de Ruby e API em alguns detalhes. Estas seções
introdutórias explicam as coisas como ciclo de vida da <code>thread</code>, agendamento de threads, e os estados da <code>thread</code>. Com que o
material introdutório como pré-requisito, passamos a apresentar código de exemplo e para cobrir <code>threads</code> avançadas como
sincronização de <code>threads</code>.</p>

<p>Finalmente, é importante notar que os programas de Ruby também pode alcançar simultaneidade ao nível do processo de sistema
operacional executando executáveis externos ​​ou novas cópias de bifurcação do interpretador Ruby. Fazendo isto é dependem do
sistema operacional. Para mais informações, use <code>ri</code> para procurar os métodos <code>Kernel.system</code>, <code>Kernel.exec</code>, <code>Kernel.fork</code>,
<code>IO.popen</code>, e o módulo <code>Process</code>.</p>

<h3>Lifecycle Tópico</h3>

<p>Como descrito acima, novas <code>threads</code> são criados com <code>Thread.new</code>. Você também pode usar os sinónimos <code>Thread.start</code> e
<code>Thread.fork</code>. Não há necessidade de se iniciar uma <code>thread</code> depois de criá-la, ele começa a ser executado automaticamente
quando os recursos da CPU estejam disponíveis. O valor da invocação <code>Thread.new</code> é um objeto <code>Thread</code>. A classe <code>Thread</code>
define um número de métodos para consultar e manipular a <code>thread</code> enquanto ela está sendo executada.</p>

<p>Uma <code>thread</code> é executa o código do bloco associado à chamada para <code>Thread.new</code> e depois pára execução. O valor da última
expressão em que o bloco é o valor da <code>thread</code>, e pode ser obtido chamando o método do valor do objeto <code>Thread</code>. Se a <code>thread</code>
foi executado para conclusão, então o valor retorna o valor da <code>thread</code> de imediato. Caso contrário, os blocos de valor do
método e não retorna até que a <code>threado</code> for concluída.</p>

<p>O método de classe <code>Thread.current</code> retorna o objeto <code>Thread</code> que representa o atual <code>thread</code>. Isso permite que as <code>threads</code>
manipulam-se. O método da classe <code>Thread.main</code> retorna o objeto <code>Thread</code> que representa a principal <code>thread</code>, este é a
<code>thread</code> inicial de execução que começou quando o Programa Ruby foi iniciado.</p>

<h4>A Thread principal</h4>

<p>A <code>Thread</code> principal é especial: o interpretador Ruby pára de correr quando a <code>thread</code> principal é feita. Ele faz isso mesmo
que a <code>thread</code> principal criou outras <code>threads</code> que ainda estão em execução. Você deve garantir, portanto, que a sua princial
<code>thread</code> não termina enquanto outras <code>threads</code> ainda estão em execução. Uma maneira de fazer isso é escrever sua <code>thread</code>
principal sob a forma de um <code>loop</code> infinito. Outra maneira é explicitamente esperar para as <code>threads</code> ser concluída. Já
mencionamos que você pode chamar o método <code>value</code> de uma <code>thread</code> que espera que ela termine. Se você não se importa com o
valor de suas <code>threads</code>, você pode esperar com o método de instancia <code>join</code>.</p>

<p>O seguinte método espera até que todas as linhas, com excepção da <code>thread</code> principal e a <code>thread</code> atual (que pode ser a mesma
coisa), ter saído:</p>

<pre><code class="ruby Thread Principal">def join_all
  main = Thread.main        # Thread Principal
  current = Thread.current  # Thread atual
  all = Thread.list         # Todas as threads ainda em execução
  # Agora chama join em cada thread
  all.each {|t| t.join unless t == current or t == main }
end
</code></pre>

<h4>Threads e exceções não tratadas</h4>

<p>Se uma exceção é levantada na <code>thread</code> principal, e não é tratada em qualquer lugar, o interpretador Ruby imprime uma
mensagem e sai. Em outras <code>threads</code> que a <code>thread</code> principal, exceções não tratadas causam a <code>thread</code> para parar de executar.
Por defeito, no entanto, isto não faz o intérprete para imprimir uma mensagem ou saída. Se uma <code>thread</code> <code>t</code> sai por causa de
uma exceção não tratada, e outra <code>thread</code> de chamadas <code>t.join</code> ou <code>t.value</code>, então a exceção que ocorreu em <code>t</code> é levantada
na <code>thread</code> de <code>s</code>.</p>

<p>Se você gostaria de qualquer exceção não tratada em qualquer <code>thread</code> para fazer com que o intérprete saia, use o método de
classe <code>Thread.abort_on_exception=</code>:</p>

<pre><code class="ruby Thread">Thread.abort_on_exception = true
</code></pre>

<p>Se você quer uma exceção não tratada em uma <code>thread</code> específica faz com que o intérprete saia, utilizando o método de
exemplo, através do mesmo nome:</p>

<pre><code class="ruby Thread abort">t = Thread.new { ... }
t.abort_on_exception = true
</code></pre>

<p>É isso ai amigos.. até a proxima!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Encadeamento de Alias - #Ruby 1.9]]></title>
    <link href="http://rrmartins.com/blog/2012/09/18/encadeamento-de-alias-number-ruby-1-dot-9/"/>
    <updated>2012-09-18T08:38:00-03:00</updated>
    <id>http://rrmartins.com/blog/2012/09/18/encadeamento-de-alias-number-ruby-1-dot-9</id>
    <content type="html"><![CDATA[<!--more-->


<p>Hoje vamos continuar falando de <a href="http://www.ruby-doc.org/core-1.9.2/">Ruby</a>, é hora de continuar nos aprofundando um pouco mais de
<b>Reflexão e Metaprogramação</b> agora <b>Encadeamento de Alias</b>...</p>




<h1>Encadeamento de Alias</h1>


<p>Como já visto, metaprogramação em Ruby muitas vezes envolve a dinâmica definição de métodos. Assim como comum é a dinâmica modificação de métodos.
Métodos são modificados com uma técnica que chamaremos de encadeamento de alias. Ele funciona assim:</p>

<pre><code>* Primeiro, criar um alias para o método a ser modificado. este apelido fornece um nome para
a versão não modificada do método.

* Em seguida, definem uma nova versão do método. Esta nova versão deve chamar a versão não modificada
através dos alias, mas pode adicionar qualquer funcionalidade que for necessário, antes e depois de que
faz isso.
</code></pre>

<p>Note-se que estes passos podem ser aplicados repetidamente (desde que um alias diferente é usado de cada vez), criando uma cadeia de métodos e aliases.</p>

<p>Este post inclui três exemplos de encadeamento de alias. O primeiro realiza o encadeamento de apelido estaticamente, ou seja, usando pseudônimo
regulares e declarações <code>def</code>. Os segundo e terceiro exemplos são mais dinâmicos; eles são apelidos que acorrentam métodos arbitrariamente nomeados
utilizando <code>alias_method</code>, <code>define_method</code> e <code>class_eval</code>.</p>

<h3>Rastreando Arquivos Carregados e Classes Definidas</h3>


<p>O <code>Exemplo 1-1</code> é um código que mantém o controle de todos os ficheiros carregados e todas as classes definidas num programa. Quando o programa sai,
ele imprime um relatório. Você pode usar este código para &ldquo;instrumento&rdquo; de um existente programa para que você entenda melhor o que está fazendo. Uma
maneira de usar este código é inserir esta linha no começo do programa:</p>

<pre><code class="ruby classtrace">require 'classtrace'
</code></pre>

<p>Uma solução mais fácil, no entanto, é usar a opção -r para o seu intérprete Ruby(<code>irb</code>):</p>

<pre><code class="ruby Opção -r">ruby -rclasstrace my_program.rb  --traceout /tmp/trace
</code></pre>

<p>A opção -r carrega a biblioteca especificado antes de começar a executar o programa.</p>

<p>O <code>Exemplo 1-1</code> usa apelido de encadeamento estático para rastrear todas as chamadas dos métodos <code>Kernel.require</code> e <code>Kernel.load</code>. Ele define um hook
<code>Object.inherited</code> para rastrear as definições de novas classes. E ele usa <code>Kernel.at_exit</code> para executar um bloco de código quando o programa termina.
Além dos encadeamentos de alias <code>require</code> e <code>load</code> e defini <code>Object.inherited</code>, a única modificação do espaço global feita por este código é a
definição de um módulo chamado <code>ClassTrace</code>. Todo o estado necessário para o rastreio é armazenado em constantes dentro deste módulo, de modo que não
poluem o <code>namespace</code> com variáveis globais.</p>

<pre><code class="ruby Exemplo 1-1. Rastreando Arquivos Carregados e Classes Definidas"># Definimos este módulo para manter o estado global do require, de modo que
# Nós não alteramos o espaço global mais do que o necessário.
module ClassTrace
   # Esta matriz mantém a nossa lista de arquivos carregados e classes definidas.
   # Cada elemento é um subarray segurando a classe definida ou o
   # Arquivo carregado e o quadro de pilha onde ele foi definido ou carregado.
   T = []  # Array para armazenar os arquivos carregados

   # Agora defini a constante OUT para especificar onde saída do rastreamento vai.
   # O padrão é stderr, mas também pode vir a partir de argumentos na linha de comando
   if x = ARGV.index("--traceout")    # Se existe argumento
     OUT = File.open(ARGV[x+1], "w")  # Abre o arquivo especificado
     ARGV[x,2] = nil                  # E remova os argumentos
   else
     OUT = STDERR                     # Caso contrário, o padrão para STDERR
   end
end

# Passo 1 encadeamento Alias: definir aliases para os métodos originais
alias original_require require
alias original_load load

# Passo 2 encadeamento Alias 2: definir novas versões dos métodos
def require(file)
  ClassTrace::T &lt;&lt; [file,caller[0]]     # Lembre-se de onde que estava carregado
  original_require(file)                # Chame o método original
end

def load(*args)
  ClassTrace::T &lt;&lt; [args[0],caller[0]]  # Lembre-se de onde que estava carregado
  original_load(*args)                  # Chame o método original
end

# Este método hook é chamado de cada vez que uma nova classe é definida
def Object.inherited(c)
  ClassTrace::T &lt;&lt; [c,caller[0]]        # Lembre-se onde que foi definido
end

# Kernel.at_exit registra um bloco a ser executado quando o programa sai
# Vamos utilizá-lo para comunicar os dados de arquivo e de classe que recolhemos
at_exit {
  o = ClassTrace::OUT
  o.puts "="*60
  o.puts "Files Loaded and Classes Defined:"
  o.puts "="*60
  ClassTrace::T.each do |what,where|
    if what.is_a? Class  # Report class (with hierarchy) defined
      o.puts "Defined: #{what.ancestors.join('&lt;-')} at #{where}"
    else                 # Report file loaded
      o.puts "Loaded: #{what} at #{where}"
    end
  end
}
</code></pre>

<h3>Métodos encadeamento de segurança da Thread</h3>


<p>O alias de encadeamento é feito pelo método <code>Module.synchronize_method</code>, o qual, por sua vez usa um método auxiliar <code>Module.create_alias</code> para definir
um alias adequado para qualquer método dado (incluindo métodos como o operador +).</p>

<p>Depois de definir estes novo métodos <code>Module</code>, Exemplo 1-2 redefine o método <code>synchronized</code> novamente. Quando o método é invocado dentro de uma classe
ou de um módulo, ele chama <code>synchronize_method</code> em cada um dos símbolos que é passado. Curiosamente, contudo, pode também ser chamado sem argumentos,
quando utilizado desta forma, acrescenta sincronização para qualquer método de instância é definido a seguir. (Utiliza o <code>hook</code> para receber
notificação quando um novo método <code>method_added</code> é adicionado.) Note que o código deste exemplo depende do método <code>Object.mutex</code> e a classe
<code>SynchronizedObject</code>.</p>

<pre><code class="ruby Exemplo 1-2. Alias de encadeamento de segurança da Thread"># Define um alias corrente Module.synchronize_method de métodos de instância
# Assim que sincronizar a instância antes da execução.
class Module
  # Esta é uma função auxiliar para o encadeamento alias.
  # Dado o nome de um método (como uma string ou símbolo) e um prefixo, cria
  # Um alias exclusivo para o método, e retornar o nome do alias
  # Como um símbolo. Quaisquer caracteres de pontuação em nome método original
  # Serão convertidos em números para que os operadores podem ser alias.
  def create_alias(original, prefix="alias")
    # Cole o prefixo do nome original e converter pontuação
    aka = "#{prefix}_#{original}"
    aka.gsub!(/([\=\|\&amp;\+\-\*\/\^\!\?\~\%\&lt;\&gt;\[\]])/) {
      num = $1[0]                       # Ruby 1.8 character -&gt; ordinal
      num = num.ord if num.is_a? String # Ruby 1.9 character -&gt; ordinal
      '_' + num.to_s
    }
    
    # Mantenha acrescentando ressalta até chegarmos a um nome que não está em uso
    aka += "_" while method_defined? aka or private_method_defined? aka

    aka = aka.to_sym           # Converter o nome de alias de um símbolo
    alias_method aka, original # Na verdade criar o alias
    aka                                              # Retorna o nome do alias
  end

  # Alias correntam o método nomeado para adicionar sincronização
  def synchronize_method(m)
    # Primeiro, fazemos um alias para a versão dessincronizado do método.
    aka = create_alias(m, "unsync")
    # Agora redefini o original para invocar o alias em um bloco sincronizado.
    # Queremos o método definido como sendo capaz de aceitar os blocos, de modo que
    # Não pode usar define_method, e deve avaliar vez uma string com
    # Class_eval. Note-se que tudo entre% Q {} e da correspondência
    # É uma string entre aspas, e não um bloco.
    class_eval %Q{
      def #{m}(*args, &amp;block)
        synchronized(self) { #{aka}(*args, &amp;block) }
      end
    }
  end
end

# Este método global sincronizado agora pode ser usado de três maneiras diferentes.
def synchronized(*args)
  # Caso 1: com um argumento e um bloco, sincronizar sobre o objeto
  # E executar o bloco
    if args.size == 1 &amp;&amp; block_given?
    args[0].mutex.synchronize { yield }

  # Caso dois: com um argumento que não é um símbolo e nenhum bloco
  # Devolve um invólucro de SynchronizedObject
  elsif args.size == 1 and not args[0].is_a? Symbol and not block_given?
    SynchronizedObject.new(args[0])

  # Caso três: quando invocado em um módulo com nenhum bloco, alias a cadeia
  # Chamado métodos para adicionar sincronização. Ou, se não há argumentos,
  # Então apelido acorrentam o próximo método definido.
  elsif self.is_a? Module and not block_given?
    if (args.size &gt; 0) # Synchronize the named methods
      args.each {|m| self.synchronize_method(m) }
    else
      # Se nenhum método é especificado pelo synchronize o método seguinte define
      eigenclass = class&lt;&lt;self; self; end
      eigenclass.class_eval do # Use eigenclass para definir métodos de classe
        # Define method_added para notificação quando próximo método é definido
        define_method :method_added do |name|
          # Primeiro remover esse método hook
          eigenclass.class_eval { remove_method :method_added }
          # Em seguida, sincronize o método que acabou de ser adicionado
          self.synchronize_method name
        end
      end
    end

  # Caso 4: qualquer outra invocação é um erro
  else
    raise ArgumentError, "Invalid arguments to synchronize()"
  end
end
</code></pre>

<h3>Métodos de encadeamento para Rastreamento</h3>


<p>O Exemplo 1-3 suporta o rastreio de métodos denominados de um objeto. Ele define <code>trace!</code> e <code>untrace!</code> a cadeia e desencadeiam métodos chamados de um
objeto.</p>

<p>A coisa interessante sobre esse exemplo é que ele faz o seu encadeamento de um modo diferente a partir do Exemplo 1-2. Ele simplesmente define métodos
únicos no objeto e usa <code>super</code> dentro do <code>singleton</code> para a cadeia de definição do método original de exemplo. Nenhum método são criado aliases.</p>

<pre><code class="ruby Exemplo 8-10. Encadeamento com métodos singleton para rastrear"># Define métodos trace! e untrace! de instância para todos os objetos.
# trace! "Cadeias" os métodos chamados por definir métodos singleton
# Que adiciona a funcionalidade de rastreamento e use super para chamar o original.
# untrace! exclui os métodos singleton para remover o rastreamento.
classe Object
  # os métodos trace especificados, enviando a saída para STDERR.
  def trace!(*methods)
    @_traced = @_traced || []    # Lembre-se o conjunto de métodos traçados

    # Se nenhum método foi especificado, use todos os métodos públicos definidos
    # Diretamente (não herdado) pela classe deste objeto
    methods = public_methods(false) if methods.size == 0

    methods.map! {|m| m.to_sym }    # Converta qualquer cordas para símbolos
    methods -= @_traced                     # remove métodos que já estão traçadas
    return if methods.empty?        # Voltar mais cedo se não há nada a fazer
    @_traced |= methods           # Adiciona métodos para definir métodos de traçados

    # Trace o fato de que estamos começando a traçar estes métodos
    STDERR &lt;&lt; "Tracing #{methods.join(', ')} on #{object_id}\n"

        # Singleton métodos são definidos na eigenclass
    eigenclass = class &lt;&lt; self; self; end

        methods.each do |m| # Para cada método m
      # Define uma versão trace singleton do método m.
      # Saída de informações de rastreamento e usar super para invocar o
      # Método de instância que é o rastreamento.
      # Queremos que os métodos definidos para ser capaz de aceitar blocos, de modo que
      # Não pode usar define_method, e deve avaliar, em vez de uma string.
      # Note que tudo entre %Q{} e a correspondência é uma
      # Entre aspas de string, não um bloco. Observe também que há
      # Dois níveis de interpolações de string aqui. # {} É interpolada
      # Quando o método singleton é definida. E \ # {} é interpolada
      # Quando o método singleton é invocado.
      eigenclass.class_eval %Q{
        def #{m}(*args, &amp;block)
          begin
            STDERR &lt;&lt; "Entering: #{m}(\#{args.join(', ')})\n"
            result = super
            STDERR &lt;&lt; "Exiting: #{m} with \#{result}\n"
            result
          rescue
            STDERR &lt;&lt; "Aborting: #{m}: \#{$!.class}: \#{$!.message}"
            raise
          end
        end
      }
    end
  end

  # Untrace os métodos especificados ou todos os métodos rastreados
    def untrace!(*methods)
    if methods.size == 0    # Se nenhuma métodos especificados untrace
      methods = @_traced    # todos os métodos atualmente rastreados
      STDERR &lt;&lt; "Untracing all methods on #{object_id}\n"
    else                    # Caso contrário, untrace
      methods.map! {|m| m.to_sym }  # Converter string para símbolos
      methods &amp;= @_traced   # todos os métodos especificados que são rastreados
      STDERR &lt;&lt; "Untracing #{methods.join(', ')} on #{object_id}\n"
    end

        @_traced -= methods     # Retire-os do nosso conjunto de métodos de traçados

        # Remove os métodos traçados únicos do eigenclass
        # Note que nós class_eval um bloco aqui, não uma string
        (class &lt;&lt; self; self; end).class_eval do
          methods.each do |m|
            remove_method m     # undef_method não funciona corretamente
          end
        end

        # Se nenhum método são traçados mais, remover o nosso exemplo var
        if @_traced.empty?
          remove_instance_variable :@_traced
        end
  end
end
</code></pre>

<p>É isso ai galera! Até a proxima!</p>
]]></content>
  </entry>
  
</feed>
